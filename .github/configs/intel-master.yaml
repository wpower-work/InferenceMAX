dsr1-fp8-gaudi3-vllm-ep:
  image: vault.habana.ai/gaudi-docker/1.22.2/ubuntu22.04/habanalabs/vllm-installer-2.7.1:latest
  model: deepseek-ai/DeepSeek-R1-0528
  model-prefix: dsr1
  runner: gaudi3
  precision: fp8
  framework: vllm
  seq-len-configs:
  - isl: 1024
    osl: 1024
    search-space:
    - { tp: 8, ep: 8, conc-start: 4, conc-end: 64 }
  - isl: 1024
    osl: 8192
    search-space:
    - { tp: 8, ep: 8, conc-start: 4, conc-end: 64 }
  - isl: 8192
    osl: 1024
    search-space:
    - { tp: 8, ep: 8, conc-start: 4, conc-end: 64 }
    
dsr1-fp8-gaudi3-vllm:
  image: vault.habana.ai/gaudi-docker/1.22.2/ubuntu22.04/habanalabs/vllm-installer-2.7.1:latest
  model: deepseek-ai/DeepSeek-R1-0528
  model-prefix: dsr1
  runner: gaudi3
  precision: fp8
  framework: vllm
  seq-len-configs:
  - isl: 1024
    osl: 1024
    search-space:
    - { tp: 8, conc-start: 4, conc-end: 64 }
  - isl: 1024
    osl: 8192
    search-space:
    - { tp: 8, conc-start: 4, conc-end: 64 }
  - isl: 8192
    osl: 1024
    search-space:
    - { tp: 8, conc-start: 4, conc-end: 64 }
    
gptoss-fp4-gaudi3-vllm:
  image: vault.habana.ai/gaudi-docker/1.21.3/ubuntu22.04/habanalabs/pytorch-installer-2.6.0:latest
  model: unsloth/gpt-oss-20b-BF16
  model-prefix: gptoss
  runner: gaudi3
  precision: fp4
  framework: vllm
  seq-len-configs:
  - isl: 1024
    osl: 1024
    search-space:
    - { tp: 1, conc-start: 4, conc-end: 128 }
    - { tp: 2, conc-start: 4, conc-end: 128 }
    - { tp: 4, conc-start: 4, conc-end: 64 }
    - { tp: 8, conc-start: 4, conc-end: 8 }
  - isl: 1024
    osl: 8192
    search-space:
    - { tp: 1, conc-start: 4, conc-end: 128 }
    - { tp: 2, conc-start: 4, conc-end: 128 }
    - { tp: 4, conc-start: 4, conc-end: 64 }
    - { tp: 8, conc-start: 4, conc-end: 8 }
  - isl: 8192
    osl: 1024
    search-space:
    - { tp: 1, conc-start: 4, conc-end: 128 }
    - { tp: 2, conc-start: 4, conc-end: 128 }
    - { tp: 4, conc-start: 4, conc-end: 64 }
    - { tp: 8, conc-start: 4, conc-end: 4 }
    
llama-fp8-gaudi3-vllm:
  image: vault.habana.ai/gaudi-docker/1.22.2/ubuntu22.04/habanalabs/vllm-installer-2.7.1:latest
  model: meta-llama/Llama-3.1-70B
  model-prefix: llama
  runner: gaudi3
  precision: fp8
  framework: vllm
  seq-len-configs:
  - isl: 1024
    osl: 1024
    search-space:
    - { tp: 1, conc-start: 4, conc-end: 128 }
    - { tp: 2, conc-start: 4, conc-end: 128 }
    - { tp: 4, conc-start: 4, conc-end: 64 }
    - { tp: 8, conc-start: 4, conc-end: 8 }
  - isl: 1024
    osl: 8192
    search-space:
    - { tp: 1, conc-start: 4, conc-end: 128 }
    - { tp: 2, conc-start: 4, conc-end: 128 }
    - { tp: 4, conc-start: 4, conc-end: 64 }
    - { tp: 8, conc-start: 4, conc-end: 8 }
  - isl: 8192
    osl: 1024
    search-space:
    - { tp: 1, conc-start: 4, conc-end: 128 }
    - { tp: 2, conc-start: 4, conc-end: 128 }
    - { tp: 4, conc-start: 4, conc-end: 64 }
    - { tp: 8, conc-start: 4, conc-end: 4 }
